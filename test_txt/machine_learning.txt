# separator
逻辑回归虽名为“回归”，实为线性分类模型，通过 sigmoid 函数将线性组合映射为类别概率，常用于二分类任务。

# separator
决策树通过递归划分特征空间构建树形结构，易于解释，但容易过拟合，通常作为集成方法（如随机森林）的基础组件。

# separator
支持向量机（SVM）通过最大化分类间隔寻找最优超平面，在高维空间中表现良好，配合核技巧可处理非线性问题。

# separator
K 折交叉验证将数据划分为 K 个子集，轮流用其中 K-1 份训练、1 份验证，能更稳健地评估模型泛化性能。

# separator
主成分分析（PCA）是一种无监督降维技术，通过保留数据中方差最大的正交方向，减少特征维度同时尽量保留信息。

# separator
K 均值聚类（K-means）通过迭代优化簇中心与样本距离，将数据划分为 K 个簇，适用于球形分布且需预先指定 K 值。

# separator
特征缩放（如标准化或归一化）对基于距离的算法（如 KNN、SVM）至关重要，可避免某些特征因量纲过大主导模型训练。

# separator
偏差-方差权衡描述了模型复杂度与泛化误差的关系：高偏差导致欠拟合，高方差导致过拟合，需在二者间取得平衡。

# separator
梯度提升树（如 XGBoost、LightGBM）通过顺序训练弱学习器并逐步修正残差，在结构化数据任务中长期占据性能优势。

# separator
混淆矩阵提供了分类模型在各类别上的预测与真实标签对比，可进一步计算准确率、召回率、F1 分数等指标。